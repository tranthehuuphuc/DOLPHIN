{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Import Pakages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "\n",
    "from modules.dolphin_patterns import DolphinMatcher, DOLPHIN_PATTERNS\n",
    "from modules.feature_extraction import compute_phonics_features, compute_structural_features\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.model_selection import train_test_split, cross_val_score\n",
    "from sklearn.metrics import classification_report, confusion_matrix\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load and Overview Datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('dga_data.csv')\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(df.describe())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(df.info())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Preprocessing datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.isna().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.dropna()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.drop(['domain'], axis=1, inplace=True)\n",
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Remove domains without public suffix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tldextract\n",
    "\n",
    "def has_valid_suffix(domain):\n",
    "    ext = tldextract.extract(domain)\n",
    "    return bool(ext.suffix)\n",
    "\n",
    "df['valid_suffix'] = df['host'].apply(has_valid_suffix)\n",
    "df = df[df['valid_suffix'] == True]\n",
    "df.drop(['valid_suffix'], axis=1, inplace=True)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Remove duplicate domains"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.drop_duplicates(subset=['host'], inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.countplot(df['isDGA'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.countplot(df['subclass'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Label Encoding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['isDGA'] = df['isDGA'].map({'dga': 1, 'legit': 0})\n",
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Extract Features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize the DolphinMatcher\n",
    "dolphin_matcher = DolphinMatcher(DOLPHIN_PATTERNS)\n",
    "\n",
    "# List to store features\n",
    "features = []\n",
    "\n",
    "# Iterate over rows in the DataFrame\n",
    "for _, row in df.iterrows():\n",
    "    # Extract the domain name\n",
    "    domain = row[\"host\"]\n",
    "    \n",
    "    # Apply the DOLPHIN matching function to the domain name\n",
    "    matches = dolphin_matcher.construct_output_function(domain)\n",
    "    \n",
    "    # Compute phonics features\n",
    "    phonics_features = compute_phonics_features(matches)\n",
    "    \n",
    "    # Compute structural/statistical features\n",
    "    structural_features = compute_structural_features(domain)\n",
    "    \n",
    "    # Combine all features into one dictionary\n",
    "    all_features = {**phonics_features, **structural_features}\n",
    "    \n",
    "    # Add label to features\n",
    "    all_features[\"isDGA\"] = row[\"isDGA\"]\n",
    "    \n",
    "    # Append to features list\n",
    "    features.append(all_features)\n",
    "\n",
    "# Convert the features list to a DataFrame\n",
    "features_df = pd.DataFrame(features)\n",
    "\n",
    "# Display the resulting DataFrame\n",
    "print(features_df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Train model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Separate features and labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = features_df.drop('isDGA', axis=1)\n",
    "y = features_df['isDGA']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create a pipeline for scaling and classification"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "pipeline = Pipeline([\n",
    "    ('scaler', StandardScaler()),\n",
    "    ('classifier', RandomForestClassifier(         \n",
    "        n_estimators=100,\n",
    "        random_state=42,\n",
    "        class_weight='balanced',\n",
    "        max_depth=None,\n",
    "        min_samples_split=5\n",
    "    ))\n",
    "])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Perform 5-fold cross-validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cross_val_scores = cross_val_score(pipeline, X, y, cv=5)\n",
    "print(\"Cross-validation scores:\", cross_val_scores)\n",
    "print(\"Average cross-validation score:\", np.mean(cross_val_scores))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Train-test split for final evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42, stratify=y)\n",
    "pipeline.fit(X_train, y_train)\n",
    "y_pred = pipeline.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Detailed metrics\n",
    "print(\"\\nClassification Report:\")\n",
    "print(classification_report(y_test, y_pred))\n",
    "print(\"\\nConfusion Matrix:\")\n",
    "print(confusion_matrix(y_test, y_pred))\n",
    "\n",
    "# FPR and FNR\n",
    "tn, fp, fn, tp = confusion_matrix(y_test, y_pred).ravel()\n",
    "accuracy = (tp + tn) / (tp + tn + fp + fn)\n",
    "fpr = fp / (fp + tn)\n",
    "fnr = fn / (tp + fn)\n",
    "print(f\"\\nAccuracy: {accuracy:.4f}\")\n",
    "print(f\"False Positive Rate (FPR): {fpr:.4f}\")\n",
    "print(f\"False Negative Rate (FNR): {fnr:.4f}\")\n",
    "\n",
    "# Feature importance\n",
    "rf_classifier = pipeline.named_steps['classifier']\n",
    "feature_importance = pd.DataFrame({\n",
    "    'feature': X.columns,\n",
    "    'importance': rf_classifier.feature_importances_\n",
    "}).sort_values(by='importance', ascending=False)\n",
    "print(\"\\nFeature Importance:\")\n",
    "print(feature_importance)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
